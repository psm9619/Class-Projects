---
title: "Project_wordcloud"
author: "Park, Soomin"
date: '2019 7 9 '
output: html_document
---

```{r setup, include=FALSE}
library(rvest)
library(rJava)
library(dplyr)
library(KoNLP) 
library(ggwordcloud)
library(wordcloud)
library(wordcloud2)
library(tm)
library(stringr)
library(ggplot2)
library(ggpubr)

useSejongDic()
#mergeUserDic(data.frame("")) -> 내가 필요로 하는 단어가 사전에 없을 시 추가하는 것 (ex. 지명)
library(RColorBrewer)
library(devtools)
devtools::install_github("lchiffon/wordcloud2")

trim <- function(x) gsub("^\\s+|\\s+$", "", x)
```

## 영화 평론 가져오기 
### 토이 스토리 4, Naver Movie

#### 1. URL 가져오기 - iframe.ifr 주소
```{r}

url_base <- 'https://movie.naver.com' 
start_url <- '/movie/bi/mi/point.nhn?code='
code <- '101966#tab'
url <- paste0(url_base, start_url, code, encoding="euc-kr")
html <- read_html(url) %>%
  html_node('iframe.ifr') %>% html_attr('src') -> url2
```

#### 2. 전체 데이터 수 & 페이지 수 구하기
```{r}
ifr_url <- paste0(url_base, url2) 

count <- read_html(ifr_url) %>%  html_node("div.score_total") %>%
         html_node(".total") %>% html_text('em')

index <- str_locate(count, "총") 
count <- str_sub(count, index[1]+1, -2)
totcount <- as.numeric(gsub(",","", count)) 

(pages <- ceiling(totcount/10))
```

#### 3. 
```{r}
tot_review <- data.frame()
for (pg in 1:pages) {
  url <- paste0 (ifr_url, '&page=', pg)
  if (pg %% 100 == 0)
    print (pg)
  html2 <- read_html(url) %>%
    html_node('div.score_result') %>%
    html_nodes('li') -> lis
  
  score <- c()  ; review <- c()  ; writer <- c()  ;  time <- c()
  for (li in lis) {
    score <- c(score, html_node(li, '.star_score') %>% html_text('em') %>% trim())
    
    (tmp <- li %>%
        html_node('.score_reple') %>%
        html_text ('p')  %>%
        trim())
    
    index <- str_locate(tmp, "\r")
    (review <- c(review, 
                 str_sub(tmp, 1, index[1]-1)))
    tmp <- trim(str_sub(tmp, index[1], -1))
    index <- str_locate(tmp, "\r")
    (writer <- c(writer, str_sub(tmp, 1, index[1]-1)))
    tmp <- trim(str_sub(tmp, index[1], -1))
    index <- str_locate(tmp, "\r")
    (time <- c(time, str_sub(tmp, 1, index[1]-1)))
  }
  
  review = data.frame(score=score, review=review, writer=writer, time=time, stringsAsFactors = F)
  tot_review <- rbind.data.frame(tot_review, review) 
}
```

#### 4. 
```{r}
tot_review$score <- factor(tot_review$score, levels = c(1:10), ordered = T)
ordered <- tot_review %>%
  arrange(desc(score))
```

#### 5. 
```{r}
rev <- ordered$review
str(rev)
write.csv(ordered, "navermovie_toystory.csv")
```

<br> <br>

## 영화 평론 분석

#### 1. 데이터 읽어오기
```{r}
data1 <- read.csv("navermovie_toystory.csv", stringsAsFactors = F)
data_review <- data1$review

```

```{r}
review_2 <- sapply(data_review, extractNoun, USE.NAMES = F)

```

#### * review 프로세싱에서 "java.lang.ArrayIndexOutOfBoundsException 에러가 발생하여 확인하자, spacing 이 되지 않은 경우였다.
#### 이 경우는 전체적인 데이터에 지나치게 문제가 되지 않는, 1개의 이슈이므로 우선 넘어가도록 한다.

```{r}
head(review_2) 
review_2 <- unlist(review_2)

length(table(review_2))  
```

#### * 아마도 spacing 문제로 인해 noun extraction 이 성공적으로 이루어지지 않은 경우가 몇 가지 눈에 띈다. 그러나 전체적으로는 양호한 면을 보이므로 전처리 중에 해결하도록 한다. 
#### * 현재 단어의 총 수는 8829 이다.

<br>

#### 2. text 전처리를 위한 리스트 작성

```{r}
t_gsub <- c("\\W", "\\d+",'[ㄱ-ㅎ]',"(ㅜ|ㅠ)","[[:punct:][:lower:][:upper:]]", 
             "였\\S*", "줄\\S*", "까지\\S*", "합니\\S*", "들이\\S*",
            "어쩐지", "냐\\S*", "쥐\\S*", "관람객", "토이스토\\S*" )
write(t_gsub, 'sub.txt')
sub <- readLines('sub.txt')
# 지속적인 활용을 위해 replace 해야 할 데이터를 txt 파일로 별개저장한다.
```

#### 3. gsub 및 글자 수 전처리
  a. 
```{r}
# 해당 데이터를 하나씩, review_2 를 카피한 review_replaced 에 적용 한다. 이 때, sub 하나마다 다시 review_replaced 를 처음부터 끝까지 반복 적용해야 하므로 중첩 사용된다.
review_replaced <- review_2
for (i in sub) {
   for (k in 1:length(review_2)) {
      review_replaced [k] <- gsub(i, "", review_replaced[k])
   }
} 
t <- table(review_replaced)
length(t)
```

#### * 현재 단어의 총 수는 7638 으로 위의 전처리 이전보다 1000 정도 감소했다.

<br>

 b.
#### 추가적으로 위에서 검토 중에 눈에 띄던 '관람객' + '..' 와 같이 주된 단어 뒤에 내용이 추가될시 제대로 파악되지 않는 경우를 해결하기 위해 약간의 전처리를 더 해준다.
#### 이 때 데이터의 선택은 count 빈도수가 <= 2 인 경우로 잡는다. 
```{r}
repeated <- c()
for (i in 1:length(t)) {
   if (t[i] <= 2) 
       repeated <- c(repeated, t[i])
} 

# ~6400 여개의 데이터가 뽑히는데 이 중 500개씩 훑어서 같은 맥락으로 5번 이상 반복되는 것으로 보이는 단어들만 뽑아 전처리를 추가한다.
# repeated[1:500] 
# repeated[501:1000]
# repeated[1001:1500]
# repeated[1501:2000]
# repeated[2001:2500]
# repeated[2501:3000]
# repeated[3001:3500]
# repeated[3501:4000]
# repeated[4001:4500]
# repeated[4501:5000]
# repeated[5001:5500]
# repeated[5501:6000]
# repeated[-c(1:6000)]

rep <- c( "가족", "가정", "감동", "강추", "결말", "기대", "기본", "끝", "나이", "너무", "노잼", "눈물","다른","다시", "다음", "대박", "덕후", "동심","딸",
          "레전드", "렉스", "마음","마지막", "매력", "먹먹", "명작", "뭉클", "미국", "버즈", "번외","별로","보니", "분리","빌런", "사랑","새드엔딩", "새로운",
          "생각","세대","소름", "손수건","스토리", "시리즈", "실망","아이들","아이언맨","알라딘","암","앤디","어른","어벤져스","억지", "우디","울컥", 
          "엔딩", "역대급", "완벽", "이별", "인생영화", "인형", "자유", "장난감", "재미", "존윅", "졸귀", "짱짱","최고", "추억", "친구","캐붕", "페미",
          "포키", "힐링", "필요","하품","함께", "행복","보니", "보핍")

review_replaced_2 <- review_replaced
for (i in rep) {
   r <- paste0(i, "\\S*")
   for (k in 1:length(review_replaced_2)) {
      review_replaced_2 [k] <- gsub(r, i, review_replaced_2[k])
   }
}
head(review_replaced_2) ; head(review_replaced)  # 기존의 review_replaced 와 비교시, 위의 추가 전처리 후에는 '보니야' 라는 단어가 '보니' 로 줄어들었음을 볼 수 있다.  
length(table(review_replaced_2))

```
#### * 현재 단어의 총 수는 6677 으로 위의 전처리 이전보다 1000 정도 감소했다.

 c.
```{r}

review_replaced_3 <- review_replaced_2

review_replaced_3 <- gsub ("개재\\S*","재미", review_replaced_3)
review_replaced_3 <- gsub ("고마\\S*", "고마움", review_replaced_3)
review_replaced_3 <-gsub ( "깜\\S*" , "깜짝", review_replaced_3)
review_replaced_3 <-gsub ("재\\S*", "재미", review_replaced_3)
review_replaced_3 <-gsub ("기다\\S*", "기다림", review_replaced_3)
review_replaced_3 <-gsub ("꿀\\S*", "재미", review_replaced_3)
review_replaced_3 <-gsub ( "놀\\S*","놀다", review_replaced_3)
review_replaced_3 <-gsub ("느끼\\S*", "느낌", review_replaced_3)
review_replaced_3 <-gsub ("돈\\S*", "돈아까움", review_replaced_3)
review_replaced_3 <-gsub (  "돌아\\S*" , "돌아간기분", review_replaced_3)
review_replaced_3 <-gsub ("두번\\S*", "두번보세요", review_replaced_3)
review_replaced_3 <-gsub ("떠나보\\S*", "떠나보냄", review_replaced_3)
review_replaced_3 <-gsub ("떠\\S*", "떠남", review_replaced_3)
review_replaced_3 <-gsub ("또보\\S*" , "또보고싶음", review_replaced_3)
review_replaced_3 <-gsub ( "만나\\S*", "만남", review_replaced_3)
review_replaced_3 <-gsub ("많\\S*", "많음", review_replaced_3)
review_replaced_3 <-gsub ( "보고싶\\S*", "보고싶을거야", review_replaced_3)
review_replaced_3 <-gsub ( "못느\\S*", "못느낌", review_replaced_3)
review_replaced_3 <-gsub ("빵\\S*","빵빵터짐", review_replaced_3)
review_replaced_3 <-gsub ("슬\\S*", "슬픔", review_replaced_3)
review_replaced_3 <-gsub ( "애\\S*","아이들", review_replaced_3)
review_replaced_3 <-gsub ( "어린\\S*", "어린시절", review_replaced_3)
review_replaced_3 <-gsub ("울\\S*", "울음", review_replaced_3)
review_replaced_3 <-gsub ( "잊\\S*", "잊혀짐", review_replaced_3)
review_replaced_3 <-gsub ( "재밌\\S*", "재미", review_replaced_3)
review_replaced_3 <-gsub ("좋\\S*", "좋음", review_replaced_3)
review_replaced_3 <-gsub ("픽사\\S*", "픽사다움", review_replaced_3)

head(review_replaced_3)
length(table(review_replaced_3))

```
#### * 현재 단어의 총 수는 6037 으로 위의 전처리 이전보다 600 정도 감소했다.
#### * 예상보다 시간대비 그리 효율적이지는 않았으나 시도에 의의를 두기로 한다.

 d. 
```{r}

# 이제 띄어쓰기 등의 문제로 extract noun 이 성공적으로 되지 못한 데이터 (nchar <= 1 | nchar >=10) 을 제거한다.
review_final <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 10}, review_replaced_3)
table.review <- table(review_final) 
length(table.review)
```

#### * 현재 단어의 총 수는 5558 으로 위의 전처리 이전보다 500 정도 감소했다.


#### 4. 마침내, Word Cloud!
```{r}
df.review <- as.data.frame(table.review)  # using just df.review took too long time for loading
df.review.2 <-   df.review %>%
   filter (Freq >= 10)
```
#### * df.review.2 는 df.review 에서도 Freq 가 10 이상인 데이터만 따로 뽑아낸 것. 이것으로 아래의 그래픽을 작성한다.

```{r}

wordcloud2(df.review.2, 
           size=2, col="random-light", 
           backgroundColor="black")
```

### 대체적으로 긍정적이고 감정을 대변하는 단어가 높은 빈도로 나타난다. 예를 들면 '감동', '사랑', '슬픔', '눈물' 등이 있고 해당 영화가 전작으로부터 거의 9년 만에 개봉함과 관련해 예고편부터 시사된 바 있었던 '어린 시절의 향수' 에 관련한 단어들도 보인다. 예를 들면 '어른','어린시절', '여운', '추억', '나이', '마지막','성장' 등이 있다. 또한 '디즈니' 라는 단어와 주인공들의 이름인 '우디', '버즈', '보핍' 등이 자주 보이는 것으로 보아 관객들이 제작사에게 관심이 있고, 주인공들에게도 감정적인 이입을 할 수 있었던, 좋은 완성도를 보이는 작품으로 인식된다.


```{r}
wordcloud2(df.review.2, figPath = "토이스토리_우디.png", size = 1.5,
           color = "random-dark")
```

* 두 번째 wordcloud2 는 토이스토리_우디 의 실루엣을 mask 로 이용한 그래픽이나, library(wordcloud2) 의 writer 가 인정한 아직 고쳐지지 않은 버그의 영향으로, html 에서 보이지 않고, 일반 R Script 에서 또한 png 로 직접 저장이 되지 않는다. 따라서 screen capture 을 이용하여 별개 저장하였다.



<br><br>

###  이제는 평점별로 10~8, 7~4, 3~1 로 나누어 사람들의 호응도에 따른 언어적 표현 빈도를 알아보자. (pos, mid, neg)

#### 아래는 평점이 8~10 인, Positive review 로 분류된 데이터이다.
```{r}
data2 <- data1 %>%
   filter(score >= 8)
pos_review_data <- data2$review   

pos_review <- sapply(pos_review_data, extractNoun, USE.NAMES = F)
pos_review <- unlist(pos_review)

# 전처리는 위에서 사용한 것과 같은 방법으로 한다.

sub <- readLines('sub.txt')

pos_2 <- pos_review
for (i in sub) {
   for (k in 1:length(pos_2)) {
      pos_2 [k] <- gsub(i, "", pos_2[k])
   }
} 
#----
pos_3 <- pos_2
for (i in rep) {
   r <- paste0(i, "\\S*")
   for (k in 1:length(pos_3)) {
      pos_3 [k] <- gsub(r, i, pos_3[k])
   }
}
#----
pos_4 <- pos_3

pos_4 <- gsub ("개재\\S*","재미", pos_4)
pos_4 <- gsub ("고마\\S*", "고마움", pos_4)
pos_4 <-gsub ( "깜\\S*" , "깜짝", pos_4)
pos_4 <-gsub ("재\\S*", "재미", pos_4)
pos_4 <-gsub ("기다\\S*", "기다림", pos_4)
pos_4 <-gsub ("꿀\\S*", "재미", pos_4)
pos_4 <-gsub ( "놀\\S*","놀다", pos_4)
pos_4 <-gsub ("느끼\\S*", "느낌", pos_4)
pos_4 <-gsub ("돈\\S*", "돈아까움", pos_4)
pos_4 <-gsub (  "돌아\\S*" , "돌아간기분", pos_4)
pos_4 <-gsub ("두번\\S*", "두번보세요", pos_4)
pos_4 <-gsub ("떠나보\\S*", "떠나보냄", pos_4)
pos_4 <-gsub ("떠\\S*", "떠남", pos_4)
pos_4 <-gsub ("또보\\S*" , "또보고싶음", pos_4)
pos_4 <-gsub ( "만나\\S*", "만남", pos_4)
pos_4 <-gsub ("많\\S*", "많음", pos_4)
pos_4 <-gsub ( "보고싶\\S*", "보고싶을거야", pos_4)
pos_4 <-gsub ( "못느\\S*", "못느낌", pos_4)
pos_4 <-gsub ("빵\\S*","빵빵터짐", pos_4)
pos_4 <-gsub ("슬\\S*", "슬픔", pos_4)
pos_4 <-gsub ( "애\\S*","아이들", pos_4)
pos_4 <-gsub ( "어린\\S*", "어린시절", pos_4)
pos_4 <-gsub ("울\\S*", "울음", pos_4)
pos_4 <-gsub ( "잊\\S*", "잊혀짐", pos_4)
pos_4 <-gsub ( "재밌\\S*", "재미", pos_4)
pos_4 <-gsub ("좋\\S*", "좋음", pos_4)
pos_4 <-gsub ("픽사\\S*", "픽사다움", pos_4)

pos_review_final <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 10}, pos_4)


```

#### 아래는 평점 4~7 대의 평론 분석이다.
```{r}

data3 <- data1 %>%
   filter(score >= 4 & score <= 7)
mid_review_data <- data3$review   

mid_review <- sapply(mid_review_data, extractNoun, USE.NAMES = F)
mid_review <- unlist(mid_review)

# 전처리는 위에서 사용한 것과 같은 방법으로 한다.

sub <- readLines('sub.txt')

mid_2 <- mid_review
for (i in sub) {
   for (k in 1:length(mid_2)) {
      mid_2 [k] <- gsub(i, "", mid_2[k])
   }
} 
#----
mid_3 <- mid_2
for (i in rep) {
   r <- paste0(i, "\\S*")
   for (k in 1:length(mid_3)) {
      mid_3 [k] <- gsub(r, i, mid_3[k])
   }
}
#----
mid_4 <- mid_3

mid_4 <- gsub ("개재\\S*","재미", mid_4)
mid_4 <- gsub ("고마\\S*", "고마움", mid_4)
mid_4 <-gsub ( "깜\\S*" , "깜짝", mid_4)
mid_4 <-gsub ("재\\S*", "재미", mid_4)
mid_4 <-gsub ("기다\\S*", "기다림", mid_4)
mid_4 <-gsub ("꿀\\S*", "재미", mid_4)
mid_4 <-gsub ( "놀\\S*","놀다", mid_4)
mid_4 <-gsub ("느끼\\S*", "느낌", mid_4)
mid_4 <-gsub ("돈\\S*", "돈아까움", mid_4)
mid_4 <-gsub (  "돌아\\S*" , "돌아간기분", mid_4)
mid_4 <-gsub ("두번\\S*", "두번보세요", mid_4)
mid_4 <-gsub ("떠나보\\S*", "떠나보냄", mid_4)
mid_4 <-gsub ("떠\\S*", "떠남", mid_4)
mid_4 <-gsub ("또보\\S*" , "또보고싶음", mid_4)
mid_4 <-gsub ( "만나\\S*", "만남", mid_4)
mid_4 <-gsub ("많\\S*", "많음", mid_4)
mid_4 <-gsub ( "보고싶\\S*", "보고싶을거야", mid_4)
mid_4 <-gsub ( "못느\\S*", "못느낌", mid_4)
mid_4 <-gsub ("빵\\S*","빵빵터짐", mid_4)
mid_4 <-gsub ("슬\\S*", "슬픔", mid_4)
mid_4 <-gsub ( "애\\S*","아이들", mid_4)
mid_4 <-gsub ( "어린\\S*", "어린시절", mid_4)
mid_4 <-gsub ("울\\S*", "울음", mid_4)
mid_4 <-gsub ( "잊\\S*", "잊혀짐", mid_4)
mid_4 <-gsub ( "재밌\\S*", "재미", mid_4)
mid_4 <-gsub ("좋\\S*", "좋음", mid_4)
mid_4 <-gsub ("픽사\\S*", "픽사다움", mid_4)

mid_review_final <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 10}, mid_4)
```


#### 아래는 평점 3 점 이하의 평론 분석이다.
```{r}

data4 <- data1 %>%
   filter(score <= 3) 
neg_review_data <- data4$review   

neg_review <- sapply(neg_review_data, extractNoun, USE.NAMES = F)
neg_review <- unlist(neg_review)

# 전처리는 위에서 사용한 것과 같은 방법으로 한다.

sub <- readLines('sub.txt')

neg_2 <- neg_review
for (i in sub) {
   for (k in 1:length(neg_2)) {
      neg_2 [k] <- gsub(i, "", neg_2[k])
   }
} 
#----
neg_3 <- neg_2
for (i in rep) {
   r <- paste0(i, "\\S*")
   for (k in 1:length(neg_3)) {
      neg_3 [k] <- gsub(r, i, neg_3[k])
   }
}
#----
neg_4 <- neg_3

neg_4 <- gsub ("개재\\S*","재미", neg_4)
neg_4 <- gsub ("고마\\S*", "고마움", neg_4)
neg_4 <-gsub ( "깜\\S*" , "깜짝", neg_4)
neg_4 <-gsub ("재\\S*", "재미", neg_4)
neg_4 <-gsub ("기다\\S*", "기다림", neg_4)
neg_4 <-gsub ("꿀\\S*", "재미", neg_4)
neg_4 <-gsub ( "놀\\S*","놀다", neg_4)
neg_4 <-gsub ("느끼\\S*", "느낌", neg_4)
neg_4 <-gsub ("돈\\S*", "돈아까움", neg_4)
neg_4 <-gsub (  "돌아\\S*" , "돌아간기분", neg_4)
neg_4 <-gsub ("두번\\S*", "두번보세요", neg_4)
neg_4 <-gsub ("떠나보\\S*", "떠나보냄", neg_4)
neg_4 <-gsub ("떠\\S*", "떠남", neg_4)
neg_4 <-gsub ("또보\\S*" , "또보고싶음", neg_4)
neg_4 <-gsub ( "만나\\S*", "만남", neg_4)
neg_4 <-gsub ("많\\S*", "많음", neg_4)
neg_4 <-gsub ( "보고싶\\S*", "보고싶을거야", neg_4)
neg_4 <-gsub ( "못느\\S*", "못느낌", neg_4)
neg_4 <-gsub ("빵\\S*","빵빵터짐", neg_4)
neg_4 <-gsub ("슬\\S*", "슬픔", neg_4)
neg_4 <-gsub ( "애\\S*","아이들", neg_4)
neg_4 <-gsub ( "어린\\S*", "어린시절", neg_4)
neg_4 <-gsub ("울\\S*", "울음", neg_4)
neg_4 <-gsub ( "잊\\S*", "잊혀짐", neg_4)
neg_4 <-gsub ( "재밌\\S*", "재미", neg_4)
neg_4 <-gsub ("좋\\S*", "좋음", neg_4)
neg_4 <-gsub ("픽사\\S*", "픽사다움", neg_4)

neg_review_final <- Filter(function(x) {nchar(x) >= 2 & nchar(x) <= 10}, neg_4)

```

#### pos, mid, neg 레벨의 리뷰를 각각 table 화, 그리고 data frame 화 한다.
```{r}
table.pos <- table(pos_review_final)
table.mid <- table(mid_review_final) 
table.neg <- table(neg_review_final) 

df.pos <- as.data.frame(table.pos) %>% arrange(desc(Freq)) %>%
   mutate(review = pos_review_final)
df.mid <- as.data.frame(table.mid) %>% arrange(desc(Freq)) %>%
   mutate(review = mid_review_final)
df.neg <- as.data.frame(table.neg) %>% arrange(desc(Freq)) %>%
   mutate(review = neg_review_final)

df.pos_2 <- df.pos %>%
   select(review, Freq) %>%
   head(200) 
df.mid_2 <- df.mid %>%
   select(review, Freq) %>%
   head(200) 
df.neg_2 <- df.neg %>%
   select(review, Freq) %>%
   head(200)


```


** wordcloud2 의 버그 문제로 html 에 뜨지 않는 그래픽은 별개로 제출함 
```{r}
wordcloud2(df.pos_2, 
           size=1, col="random-light", 
           backgroundColor="black")

wordcloud2(df.mid_2, 
           size=1, col="random-light", 
           backgroundColor="black")

wordcloud2(df.neg_2, 
           size=1, col="random-light", 
           backgroundColor="black")

```

<br>

#### 총 세 단계로 구분된 리뷰들에서 모두 공통적으로 쓰인 단어를 common_3sets 으로 정의한다. 또한 긍정과 부정 리뷰에서 공통적으로 쓰인 단어를 common_PosNeg 라고 이름하였다.
#### 긍정적인 리뷰 (평점 8~10) 에서만 쓰인 단어 top 20 과 부정적인 리뷰 (평점 1~3) 단어 top 20 을 각각 대조하였다.
```{r}
common_3sets <- intersect(intersect(df.pos_2$review, df.mid_2$review), df.neg_2$review)
common_PosNeg <- intersect(df.pos_2$review, df.neg_2$review)
head(common_PosNeg)

only_Pos <- df.pos_2 %>%
   filter(!review %in% common_PosNeg) %>%
   arrange(desc(Freq)) %>%
   head(30)

only_Neg <- df.neg_2 %>%
   filter(!review %in% common_PosNeg) %>%
   arrange(desc(Freq)) %>%
   head(30)

Pos_Neg <- data.frame (only_Pos30 = only_Pos$review, p.Freq = only_Pos$Freq,
                       only_Neg30 =  only_Neg$review, n.Freq = only_Neg$Fre)
Pos_Neg





```

#### word cloud 비교
```{r}

a <- ggplot(Pos_Neg, aes(label = only_Pos30, size = p.Freq, color=p.Freq)) +
   geom_text_wordcloud_area(shape="diamond") +
   scale_size_area(max_size = 24) +
   theme(panel.background = element_rect(fill = 'grey3')) +
   scale_color_gradient(low = "yellow", high = "orange")

b <- ggplot(Pos_Neg, aes(label = only_Neg30, size = n.Freq, color=n.Freq)) +
   geom_text_wordcloud_area(shape="diamond") +
   scale_size_area(max_size = 24) +
   theme(panel.background = element_rect(fill = 'grey3')) +
   scale_color_gradient(low = "white", high = "blue")

ggarrange (a,b)

```


### 이로써 긍정적인 리뷰의 대표적인 언어는 일반적으로도 긍정과 칭찬의 의미를 갖는, '최고', '좋음' 등과 위의 통합 언어분석에서도 지속적으로 눈에 띈 '어린 시절', '향수' 등과 맥락을 함께하는 '여윤', '어른', '성장' 등의 의미가 대표적으로 보인다. 또 영화사인 픽사에 대한 호의적인 태도 도 눈에 띈다.

<br>

### 반면 부정적인 리뷰의 대표적인 언어는, 매우 강한 어조로 부정을 이야기하는 태도가 눈에 띄었다. 예를 들면 '최악', '노잼', '붕괴' 등의 매우 파괴적인 언어의 사용이 있었으며, '억지', '무시', '짜증' 등의 감정적인 반응도도 매우 부정적이다. 또한 '감독', '멤버', '악역', '주제' 등의 영화사 자체보다 제작자들과 구성원들에 대한 조금 더 직접적인 비난의도가 드러난다고 할 수 있다.

<br> <br>

### 이로서 6/20 일 개봉한 토이스토리 4 에 대한 현재까지의 관객 반응도를, Naver Movie 크롤링과 word cloud 분석을 통해 알아보았다.

<br> <br>




